# nanochat 架构设计和数据流分析

## 系统架构概览

```
┌─────────────────────────────────────────────────────────────────────┐
│                     nanochat 全栈架构                               │
└─────────────────────────────────────────────────────────────────────┘

                          数据流向 ↓

┌──────────────────────────────────────────────────────────────────────┐
│ 1. 数据层 (Data Layer)                                               │
├──────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  dataset.py ──→ HuggingFace Hub  (下载原始文本数据)                  │
│      ↓                                                               │
│  tokenizer.py ──→ BPE分词 (将文本转为token序列)                     │
│      ↓                                                               │
│  dataloader.py ──→ 批处理和分布式采样                               │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────────────┐
│ 2. 训练层 (Training Layer)                                          │
├──────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  预训练阶段 (Base)                                                   │
│  ┌──────────────────────────────────────────────────────────────┐   │
│  │ base_train.py                                                │   │
│  │  ├── gpt.py (模型)                                           │   │
│  │  ├── adamw.py / muon.py (优化器)                            │   │
│  │  ├── checkpoint_manager.py (保存检查点)                      │   │
│  │  └── common.py (分布式训练工具)                             │   │
│  └──────────────────────────────────────────────────────────────┘   │
│                    ↓                                                  │
│  继续训练阶段 (Mid)                                                   │
│  ┌──────────────────────────────────────────────────────────────┐   │
│  │ mid_train.py (在更多数据上继续训练)                          │   │
│  └──────────────────────────────────────────────────────────────┘   │
│                    ↓                                                  │
│  微调阶段 (Chat Tuning)                                              │
│  ┌──────────────────────────────────────────────────────────────┐   │
│  │ chat_sft.py (监督微调)  →  chat_rl.py (强化学习)            │   │
│  │ (指令跟随训练)         (奖励优化)                           │   │
│  └──────────────────────────────────────────────────────────────┘   │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────────────┐
│ 3. 评估层 (Evaluation Layer)                                        │
├──────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  base_eval.py ──→ 预训练评估                                        │
│    core_eval.py ──→ CORE基准 (8000词标准数据)                      │
│    困惑度计算                                                        │
│                                                                      │
│  chat_eval.py ──→ 聊天评估                                          │
│    任务.py ──→ 多基准评估                                           │
│                                                                      │
│  tasks/:                                                             │
│    ├── arc.py (常识推理) - 4选1, 2分支                             │
│    ├── gsm8k.py (数学推理) - 需要推理步骤                          │
│    ├── humaneval.py (代码) - 164个编程题                           │
│    ├── mmlu.py (多学科) - 57个主题                                 │
│    ├── spellingbee.py (拼写) - 单词组合                            │
│    ├── smoltalk.py (对话) - 自然对话                               │
│    └── customjson.py (自定义) - 灵活格式                           │
│                                                                      │
│  report.py ──→ 生成综合评估报告 (Markdown)                         │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────────────┐
│ 4. 推理层 (Inference Layer)                                         │
├──────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  engine.py                                                           │
│  ├── 模型加载 (checkpoint_manager.py)                               │
│  ├── Token序列处理                                                   │
│  ├── KV缓存管理                                                      │
│  ├── 批量推理支持                                                    │
│  └── 计算器工具集成                                                  │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────────────┐
│ 5. 服务层 (Service Layer)                                           │
├──────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  chat_web.py ──→ FastAPI Web服务器                                 │
│    ├── /chat 端点 (token生成)                                      │
│    ├── /ws 端点 (WebSocket)                                        │
│    ├── /ui.html (前端页面)                                         │
│    └── CORS和错误处理                                              │
│                                                                      │
│  chat_cli.py ──→ 命令行聊天                                         │
│    ├── 交互式输入                                                   │
│    ├── 流式输出                                                     │
│    └── 会话管理                                                     │
│                                                                      │
└──────────────────────────────────────────────────────────────────────┘
```

## 模块组织结构

### nanochat/ (核心库)
```
nanochat/
├── 模型组件
│   └── gpt.py
│       ├── GPTConfig (配置)
│       ├── GPT (主模型)
│       │   ├── Transformer块
│       │   ├── Self-Attention (支持GQA)
│       │   ├── MLP (ReLU^2)
│       │   ├── RoPE编码
│       │   └── RMSNorm
│       └── 训练辅助函数
│
├── 分词组件
│   └── tokenizer.py
│       ├── HuggingFaceTokenizer (训练)
│       ├── RustBPETokenizer (快速推理)
│       ├── TiktokenTokenizer (官方实现)
│       └── 特殊tokens管理
│
├── 推理组件
│   └── engine.py
│       ├── Engine (推理引擎)
│       │   ├── forward_pass (前向传播)
│       │   ├── generate (生成tokens)
│       │   ├── KV缓存
│       │   └── 计算器工具
│       └── 参数采样 (温度, top-k等)
│
├── 优化器组件
│   ├── adamw.py
│   │   ├── AdamW
│   │   └── DistAdamW (分布式)
│   └── muon.py
│       ├── Muon
│       └── DistMuon (分布式)
│
├── 数据处理组件
│   ├── dataset.py
│   │   ├── load_datasets (HF Hub)
│   │   └── 预处理
│   ├── dataloader.py
│   │   ├── 批处理
│   │   ├── 分布式采样
│   │   └── 碰撞处理
│   └── checkpoint_manager.py
│       ├── save_checkpoint
│       ├── load_checkpoint
│       └── 优化器状态管理
│
├── 评估组件
│   ├── core_eval.py
│   │   ├── evaluate_core (基准评估)
│   │   └── 困惑度计算
│   ├── loss_eval.py
│   │   └── 各损失函数
│   └── report.py
│       ├── generate_report
│       ├── format_metrics
│       └── Markdown生成
│
└── 工具组件
    ├── common.py
    │   ├── 分布式工具
    │   ├── 设备检测
    │   └── 日志函数
    ├── execution.py
    │   ├── Executor
    │   ├── 训练循环
    │   └── 回调系统
    └── configurator.py
        ├── Config类
        └── 参数解析
```

### scripts/ (可执行脚本)
```
scripts/
├── 数据准备
│   └── tok_train.py (BPE分词器训练)
│
├── 预训练流程
│   ├── base_train.py
│   ├── base_loss.py
│   └── base_eval.py
│
├── 继续训练流程
│   └── mid_train.py
│
├── 微调流程
│   ├── chat_sft.py (监督微调)
│   └── chat_rl.py (强化学习)
│
├── 评估流程
│   ├── chat_eval.py (聊天评估)
│   └── tok_eval.py (分词器评估)
│
└── 推理服务
    ├── chat_web.py (FastAPI Web)
    └── chat_cli.py (CLI)
```

### tasks/ (评估基准)
```
tasks/
├── common.py (基类和工具)
│   ├── BaseTask (抽象基类)
│   ├── TaskDataset
│   └── 指标计算
│
└── 具体任务实现
    ├── arc.py (ARC-Challenge)
    ├── gsm8k.py (GSM8K)
    ├── humaneval.py (HumanEval)
    ├── mmlu.py (MMLU)
    ├── spellingbee.py (拼写)
    ├── smoltalk.py (对话)
    └── customjson.py (自定义JSON)
```

## 关键数据结构

### 1. 配置流
```
GPTConfig {
    sequence_len: 1024
    vocab_size: 50304
    n_layer: 12              (可调)
    n_head: 6
    n_kv_head: 6             (GQA)
    n_embd: 768
}
```

### 2. Token流
```
原始文本 (字符串)
    ↓ (tokenizer.py)
Token IDs (整数列表) [100, 245, 382, ...]
    ↓ (dataloader.py)
Batch张量 (BS × Seq_len)
    ↓ (gpt.py forward)
Logits张量 (BS × Seq_len × vocab_size)
    ↓ (engine.py sampling)
下一个Token ID → 重复直到结束
```

### 3. 训练流
```
Batch数据 → 前向传播 → Logits
                        ↓
                    计算损失
                        ↓
                    反向传播
                        ↓
                    优化器步骤 (Adam/Muon)
                        ↓
                    更新参数
                        ↓
                    保存检查点 (定期)
                        ↓
                    评估 (定期)
```

## 分布式训练架构

```
GPU集群 (8×H100节点)
│
├─ torchrun 管理
│   ├─ Rank 0 (Master)
│   │   ├── 模型副本
│   │   ├── 优化器状态
│   │   ├── 梯度同步协调
│   │   └── 检查点保存
│   │
│   ├─ Rank 1-7 (Workers)
│   │   ├── 模型副本
│   │   ├── 本地优化器状态
│   │   └── 本地梯度计算
│   │
│   └─ 通信后端 (NCCL)
│       └── AllReduce (梯度同步)
│
├── 数据并行
│   └── 每个GPU处理不同的批次
│
└── 梯度累积
    └── 多个前向/反向传播后才优化
```

## 优化器选择路径

```
配置选择
    ↓
┌─────────────────────────────────────┐
│  是否使用分布式训练?                  │
├─────────────────────────────────────┤
│ 是 → 多GPU/节点    否 → 单GPU        │
│     ↓                  ↓             │
│  选择优化器          选择优化器       │
│  ├─ DistAdamW        ├─ AdamW       │
│  └─ DistMuon         └─ Muon        │
│                                     │
│ Muon特点:                           │
│ ├─ 更快的收敛                       │
│ ├─ 更少的超参调优                   │
│ ├─ 较低内存使用                     │
│ └─ 适合LLM训练                      │
└─────────────────────────────────────┘
```

## 推理管道细节

```
用户输入 (文本)
    ↓
tokenizer.encode(文本) → [token_ids]
    ↓
engine.generate(
    prompt_tokens=[...],
    max_length=256,
    temperature=0.7,
    top_k=50
)
    ↓
    KV缓存初始化
    for i in range(max_length):
        logits = model.forward(tokens)
        probs = softmax(logits / temperature)
        next_token = sample(probs, top_k=50)
        tokens.append(next_token)
        更新KV缓存
    ↓
tokenizer.decode(tokens) → 输出文本
    ↓
显示给用户
```

## 评估工作流

```
模型检查点加载
    ↓
┌─────────────────────────────────────┐
│ 对每个任务:                           │
│ 1. 加载任务数据集                   │
│ 2. 对每个样本:                       │
│    a. 准备输入                       │
│    b. 生成答案                       │
│    c. 评估答案正确性                 │
│ 3. 计算任务指标                      │
└─────────────────────────────────────┘
    ↓
汇总所有任务结果
    ↓
生成report.md (表格、图表等)
    ↓
显示性能对比
```

## Web服务架构

```
┌──────────────────────────────────────┐
│ chat_web.py (FastAPI)               │
├──────────────────────────────────────┤
│                                      │
│ 路由:                                │
│ GET  /          → 返回ui.html       │
│ POST /chat      → JSON API          │
│      ├─ 输入: {"message": "..."}    │
│      └─ 输出: {"response": "..."}   │
│ WS   /ws        → WebSocket         │
│      ├─ 接收消息                    │
│      ├─ 流式生成                    │
│      └─ 发送tokens                  │
│                                      │
│ 内部:                                │
│ ├── engine = Engine(model, tokenizer)
│ ├── 会话管理                         │
│ ├── 错误处理                         │
│ └── 日志记录                         │
│                                      │
└──────────────────────────────────────┘
        ↓
┌──────────────────────────────────────┐
│ ui.html (前端)                      │
├──────────────────────────────────────┤
│ ├── 聊天界面                         │
│ ├── 消息历史                         │
│ ├── 参数调整 (温度等)               │
│ ├── WebSocket连接                   │
│ └── 流式显示                         │
└──────────────────────────────────────┘
```

## 文件依赖关系图

```
顶层脚本
    ├── base_train.py
    │   ├── gpt.py (导入GPT, GPTConfig)
    │   ├── dataset.py (数据加载)
    │   ├── dataloader.py (批处理)
    │   ├── adamw.py / muon.py (优化器)
    │   ├── checkpoint_manager.py
    │   ├── common.py (工具)
    │   └── core_eval.py (评估)
    │
    ├── mid_train.py
    │   └── (类似base_train的依赖)
    │
    ├── chat_sft.py
    │   ├── gpt.py
    │   ├── dataset.py (对话数据)
    │   ├── tokenizer.py (处理特殊tokens)
    │   └── ...
    │
    ├── chat_rl.py
    │   └── (奖励模型 + PPO)
    │
    ├── chat_web.py
    │   ├── engine.py (推理)
    │   ├── gpt.py (模型)
    │   ├── tokenizer.py
    │   ├── checkpoint_manager.py (加载)
    │   └── ui.html (嵌入式)
    │
    └── chat_cli.py
        ├── engine.py
        ├── gpt.py
        └── tokenizer.py

核心库模块间依赖
    gpt.py
        └── (独立, 只用PyTorch)
    
    engine.py
        ├── gpt.py
        ├── checkpoint_manager.py
        └── common.py
    
    tokenizer.py
        ├── rustbpe (可选)
        └── tiktoken (可选)
    
    checkpoint_manager.py
        └── common.py
    
    core_eval.py
        ├── gpt.py
        └── tasks/*
    
    report.py
        └── (独立数据处理)
```

## 完整训练流程示意

```
speedrun.sh
    │
    ├─ 第1步: 数据准备
    │   python -m nanochat.dataset -n 10
    │       ↓ 下载10个数据分片
    │
    ├─ 第2步: 分词器训练
    │   python -m scripts.tok_train
    │       ↓ 训练BPE词表
    │
    ├─ 第3步: 基础预训练 (4小时中的大部分)
    │   torchrun -m scripts.base_train --depth=12
    │       ├─ 加载数据
    │       ├─ 初始化GPT模型
    │       ├─ 多epoch遍历数据
    │       ├─ 定期评估和保存
    │       └─ checkpoint保存
    │
    ├─ 第4步: 中间训练
    │   torchrun -m scripts.mid_train
    │       ├─ 加载预训练检查点
    │       ├─ 在混合数据继续训练
    │       └─ 多基准评估
    │
    ├─ 第5步: SFT微调
    │   torchrun -m scripts.chat_sft
    │       ├─ 加载MID检查点
    │       ├─ 对话数据微调
    │       └─ 评估聊天能力
    │
    ├─ 第6步: 可选RL微调
    │   torchrun -m scripts.chat_rl
    │       ├─ 加载SFT检查点
    │       ├─ PPO训练
    │       └─ 最终评估
    │
    ├─ 第7步: 评估报告
    │   report.py生成markdown文件
    │       └─ report.md (性能总结表)
    │
    └─ 第8步: Web服务
        python -m scripts.chat_web
            ├─ 启动FastAPI服务器
            ├─ 加载最终模型
            └─ 提供http://localhost:8000/
```

## 关键设计模式

### 1. 分布式训练
- DDP (DistributedDataParallel)
- 梯度累积
- 检查点恢复

### 2. 模块化设计
- 每个组件职责单一
- 清晰的接口定义
- 易于测试和替换

### 3. 配置驱动
- Dataclass配置
- 命令行参数
- 超参灵活调整

### 4. 评估系统
- 模块化任务
- 多基准支持
- 自动报告生成

### 5. 推理优化
- KV缓存
- 批处理支持
- 采样策略多样化

